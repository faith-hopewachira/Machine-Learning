{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84b9fb-4c11-44f9-a3d3-f7e5cd5c40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ae5e8-8c62-4b52-8336-18b59b0484b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = pd.read_csv('/home/student/application_train.csv', nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619611e-253b-4aa2-9e70-5ad2953d6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4300ec1-408e-4294-944e-4df1c7f98320",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'SK_ID_CURR': 'client_id',\n",
    "    'TARGET': 'loan_status',\n",
    "    'NAME_CONTRACT_TYPE': 'loan_type',\n",
    "    'CODE_GENDER': 'gender',\n",
    "    'FLAG_OWN_CAR': 'owns_car',\n",
    "    'FLAG_OWN_REALTY': 'owns_property',\n",
    "    'CNT_CHILDREN': 'num_children',\n",
    "    'AMT_INCOME_TOTAL': 'total_income',\n",
    "    'AMT_CREDIT': 'credit_amount',\n",
    "    'AMT_ANNUITY': 'annuity_amount',\n",
    "    'AMT_GOODS_PRICE': 'goods_price',\n",
    "    'NAME_TYPE_SUITE': 'accompaniment_type',\n",
    "    'NAME_INCOME_TYPE': 'income_type',\n",
    "    'NAME_EDUCATION_TYPE': 'education_level',\n",
    "    'NAME_FAMILY_STATUS': 'family_status',\n",
    "    'NAME_HOUSING_TYPE': 'housing_type',\n",
    "    'REGION_POPULATION_RELATIVE': 'region_population_relative',\n",
    "    'DAYS_BIRTH': 'age_in_days',\n",
    "    'DAYS_EMPLOYED': 'days_employed',\n",
    "    'DAYS_REGISTRATION': 'days_registered',\n",
    "    'DAYS_ID_PUBLISH': 'days_ID_published',\n",
    "    'OWN_CAR_AGE': 'car_age',\n",
    "    'FLAG_MOBIL': 'has_mobile',\n",
    "    'FLAG_EMP_PHONE': 'has_work_phone',\n",
    "    'FLAG_WORK_PHONE': 'has_work_phone_alt',\n",
    "    'FLAG_CONT_MOBILE': 'has_contactable_mobile',\n",
    "    'FLAG_PHONE': 'has_phone',\n",
    "    'FLAG_EMAIL': 'has_email',\n",
    "    'OCCUPATION_TYPE': 'occupation',\n",
    "    'CNT_FAM_MEMBERS': 'family_size',\n",
    "    'REGION_RATING_CLIENT': 'region_rating',\n",
    "    'REGION_RATING_CLIENT_W_CITY': 'region_rating_with_city',\n",
    "    'WEEKDAY_APPR_PROCESS_START': 'application_weekday',\n",
    "    'HOUR_APPR_PROCESS_START': 'application_hour',\n",
    "    'REG_REGION_NOT_LIVE_REGION': 'region_not_living',\n",
    "    'REG_REGION_NOT_WORK_REGION': 'region_not_working',\n",
    "    'LIVE_REGION_NOT_WORK_REGION': 'living_region_not_work_region',\n",
    "    'REG_CITY_NOT_LIVE_CITY': 'city_not_living',\n",
    "    'REG_CITY_NOT_WORK_CITY': 'city_not_working',\n",
    "    'LIVE_CITY_NOT_WORK_CITY': 'living_city_not_work_city',\n",
    "    'ORGANIZATION_TYPE': 'employer_type',\n",
    "    'EXT_SOURCE_1': 'external_score_1',\n",
    "    'EXT_SOURCE_2': 'external_score_2',\n",
    "    'EXT_SOURCE_3': 'external_score_3',\n",
    "    'APARTMENTS_AVG': 'apartment_average_size',\n",
    "    'BASEMENTAREA_AVG': 'basement_average_area',\n",
    "    'YEARS_BEGINEXPLUATATION_AVG': 'years_since_building_use',\n",
    "    'YEARS_BUILD_AVG': 'building_age',\n",
    "    'COMMONAREA_AVG': 'common_area_avg',\n",
    "    'ELEVATORS_AVG': 'elevators_avg',\n",
    "    'ENTRANCES_AVG': 'entrances_avg',\n",
    "    'FLOORSMAX_AVG': 'max_floors_avg',\n",
    "    'FLOORSMIN_AVG': 'min_floors_avg',\n",
    "    'LANDAREA_AVG': 'land_area_avg',\n",
    "    'LIVINGAPARTMENTS_AVG': 'living_apartments_avg',\n",
    "    'LIVINGAREA_AVG': 'living_area_avg',\n",
    "    'NONLIVINGAPARTMENTS_AVG': 'non_living_apartments_avg',\n",
    "    'NONLIVINGAREA_AVG': 'non_living_area_avg',\n",
    "    'APARTMENTS_MODE': 'apartment_mode',\n",
    "    'BASEMENTAREA_MODE': 'basement_mode',\n",
    "    'YEARS_BEGINEXPLUATATION_MODE': 'years_building_use_mode',\n",
    "    'YEARS_BUILD_MODE': 'building_age_mode',\n",
    "    'COMMONAREA_MODE': 'common_area_mode',\n",
    "    'ELEVATORS_MODE': 'elevators_mode',\n",
    "    'ENTRANCES_MODE': 'entrances_mode',\n",
    "    'FLOORSMAX_MODE': 'max_floors_mode',\n",
    "    'FLOORSMIN_MODE': 'min_floors_mode',\n",
    "    'LANDAREA_MODE': 'land_area_mode',\n",
    "    'LIVINGAPARTMENTS_MODE': 'living_apartments_mode',\n",
    "    'LIVINGAREA_MODE': 'living_area_mode',\n",
    "    'NONLIVINGAPARTMENTS_MODE': 'non_living_apartments_mode',\n",
    "    'NONLIVINGAREA_MODE': 'non_living_area_mode',\n",
    "    'APARTMENTS_MEDI': 'apartment_median_size',\n",
    "    'BASEMENTAREA_MEDI': 'basement_median_area',\n",
    "    'YEARS_BEGINEXPLUATATION_MEDI': 'years_building_use_median',\n",
    "    'YEARS_BUILD_MEDI': 'building_age_median',\n",
    "    'COMMONAREA_MEDI': 'common_area_median',\n",
    "    'ELEVATORS_MEDI': 'elevators_median',\n",
    "    'ENTRANCES_MEDI': 'entrances_median',\n",
    "    'FLOORSMAX_MEDI': 'max_floors_median',\n",
    "    'FLOORSMIN_MEDI': 'min_floors_median',\n",
    "    'LANDAREA_MEDI': 'land_area_median',\n",
    "    'LIVINGAPARTMENTS_MEDI': 'living_apartments_median',\n",
    "    'LIVINGAREA_MEDI': 'living_area_median',\n",
    "    'NONLIVINGAPARTMENTS_MEDI': 'non_living_apartments_median',\n",
    "    'NONLIVINGAREA_MEDI': 'non_living_area_median',\n",
    "    'FONDKAPREMONT_MODE': 'house_fund_mode',\n",
    "    'HOUSETYPE_MODE': 'house_type_mode',\n",
    "    'TOTALAREA_MODE': 'total_area_mode',\n",
    "    'WALLSMATERIAL_MODE': 'walls_material_mode',\n",
    "    'EMERGENCYSTATE_MODE': 'emergency_state_mode',\n",
    "    'OBS_30_CNT_SOCIAL_CIRCLE': 'social_circle_obs_30',\n",
    "    'DEF_30_CNT_SOCIAL_CIRCLE': 'social_circle_def_30',\n",
    "    'OBS_60_CNT_SOCIAL_CIRCLE': 'social_circle_obs_60',\n",
    "    'DEF_60_CNT_SOCIAL_CIRCLE': 'social_circle_def_60',\n",
    "    'DAYS_LAST_PHONE_CHANGE': 'days_since_last_phone_change',\n",
    "    'FLAG_DOCUMENT_2': 'flag_document_2',\n",
    "    'FLAG_DOCUMENT_3': 'flag_document_3',\n",
    "    'FLAG_DOCUMENT_4': 'flag_document_4',\n",
    "    'FLAG_DOCUMENT_5': 'flag_document_5',\n",
    "    'FLAG_DOCUMENT_6': 'flag_document_6',\n",
    "    'FLAG_DOCUMENT_7': 'flag_document_7',\n",
    "    'FLAG_DOCUMENT_8': 'flag_document_8',\n",
    "    'FLAG_DOCUMENT_9': 'flag_document_9',\n",
    "    'FLAG_DOCUMENT_10': 'flag_document_10',\n",
    "    'FLAG_DOCUMENT_11': 'flag_document_11',\n",
    "    'FLAG_DOCUMENT_12': 'flag_document_12',\n",
    "    'FLAG_DOCUMENT_13': 'flag_document_13',\n",
    "    'FLAG_DOCUMENT_14': 'flag_document_14',\n",
    "    'FLAG_DOCUMENT_15': 'flag_document_15',\n",
    "    'FLAG_DOCUMENT_16': 'flag_document_16',\n",
    "    'FLAG_DOCUMENT_17': 'flag_document_17',\n",
    "    'FLAG_DOCUMENT_18': 'flag_document_18',\n",
    "    'FLAG_DOCUMENT_19': 'flag_document_19',\n",
    "    'FLAG_DOCUMENT_20': 'flag_document_20',\n",
    "    'FLAG_DOCUMENT_21': 'flag_document_21',\n",
    "    'AMT_REQ_CREDIT_BUREAU_HOUR': 'credit_requests_hour',\n",
    "    'AMT_REQ_CREDIT_BUREAU_DAY': 'credit_requests_day',\n",
    "    'AMT_REQ_CREDIT_BUREAU_WEEK': 'credit_requests_week',\n",
    "    'AMT_REQ_CREDIT_BUREAU_MON': 'credit_requests_month',\n",
    "    'AMT_REQ_CREDIT_BUREAU_QRT': 'credit_requests_quarter',\n",
    "    'AMT_REQ_CREDIT_BUREAU_YEAR': 'credit_requests_year'\n",
    "}\n",
    "\n",
    "### Apply renaming to the dataframe\n",
    "loan_df.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54673c-dc15-4468-8f08-4edbb05b58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "missing_values = loan_df.isnull().sum()\n",
    "# print(missing_values)\n",
    "\n",
    "missing_columns = missing_values[missing_values > 0]\n",
    "# print(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bdfef-5a84-4db5-9ce1-3fcdcab91c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['annuity_amount'] = loan_df.groupby(['total_income', 'income_type'])['annuity_amount'].transform(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aaca06-54b4-45c0-bfcf-a328556a07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['goods_price'] = loan_df['goods_price'].fillna(loan_df['goods_price'].quantile(0.25))\n",
    "loan_df['car_age'] = loan_df['car_age'].fillna(loan_df['car_age'].quantile(0.25))\n",
    "loan_df['credit_requests_hour'] = loan_df['credit_requests_hour'].fillna(loan_df['credit_requests_hour'].quantile(0.25))\n",
    "loan_df['credit_requests_day'] = loan_df['credit_requests_day'].fillna(loan_df['credit_requests_day'].quantile(0.25))\n",
    "loan_df['credit_requests_week'] = loan_df['credit_requests_week'].fillna(loan_df['credit_requests_week'].quantile(0.25))\n",
    "loan_df['credit_requests_month'] = loan_df['credit_requests_month'].fillna(loan_df['credit_requests_month'].quantile(0.25))\n",
    "loan_df['credit_requests_quarter'] = loan_df['credit_requests_quarter'].fillna(loan_df['credit_requests_quarter'].quantile(0.25))\n",
    "loan_df['accompaniment_type'] = loan_df['accompaniment_type'].fillna(loan_df['accompaniment_type'].mode()[0])  # Using mode for categorical data\n",
    "loan_df['entrances_median'] = loan_df['entrances_median'].fillna(loan_df['credit_requests_year'].quantile(0.25))\n",
    "loan_df['living_area_median'] = loan_df['living_area_median'].fillna(loan_df['credit_requests_year'].quantile(0.25))\n",
    "loan_df['days_since_last_phone_change'] = loan_df['days_since_last_phone_change'].fillna(loan_df['credit_requests_year'].quantile(0.25))\n",
    "loan_df['external_score_1'] = loan_df['external_score_1'].fillna(loan_df['external_score_1'].quantile(0.25))\n",
    "loan_df['external_score_2'] = loan_df['external_score_2'].fillna(loan_df['external_score_2'].quantile(0.25))\n",
    "loan_df['external_score_3'] = loan_df['external_score_3'].fillna(loan_df['external_score_3'].quantile(0.25))\n",
    "loan_df['social_circle_obs_30'] = loan_df['social_circle_obs_30'].fillna(loan_df['credit_requests_year'].quantile(0.25))\n",
    "loan_df['social_circle_def_30'] = loan_df['social_circle_def_30'].fillna(loan_df['credit_requests_year'].quantile(0.25))\n",
    "loan_df['social_circle_obs_60'] = loan_df['social_circle_obs_60'].fillna(loan_df['credit_requests_year'].quantile(0.25))\n",
    "loan_df['social_circle_def_60'] = loan_df['social_circle_def_60'].fillna(loan_df['credit_requests_year'].quantile(0.25))\n",
    "loan_df['non_living_apartments_median'] = loan_df['non_living_apartments_median'].fillna(loan_df['non_living_apartments_median'].quantile(0.25))\n",
    "loan_df['land_area_mode'] = loan_df['land_area_mode'].fillna(loan_df['land_area_mode'].quantile(0.25))\n",
    "loan_df['living_apartments_mode'] = loan_df['living_apartments_mode'].fillna(loan_df['living_apartments_mode'].quantile(0.25))\n",
    "loan_df['living_area_mode'] = loan_df['living_area_mode'].fillna(loan_df['living_area_mode'].quantile(0.25))\n",
    "loan_df['non_living_apartments_mode'] = loan_df['non_living_apartments_mode'].fillna(loan_df['non_living_apartments_mode'].quantile(0.25))\n",
    "loan_df['non_living_area_mode'] = loan_df['non_living_area_mode'].fillna(loan_df['non_living_area_mode'].quantile(0.25))\n",
    "loan_df['apartment_median_size'] = loan_df['apartment_median_size'].fillna(loan_df['apartment_median_size'].quantile(0.25))\n",
    "loan_df['entrances_avg'] = loan_df['entrances_avg'].fillna(loan_df['entrances_avg'].quantile(0.25))\n",
    "loan_df['basement_median_area'] = loan_df['basement_median_area'].fillna(loan_df['basement_median_area'].quantile(0.25))\n",
    "loan_df['years_building_use_median'] = loan_df['years_building_use_median'].fillna(loan_df['years_building_use_median'].quantile(0.25))\n",
    "loan_df['building_age_median'] = loan_df['building_age_median'].fillna(loan_df['building_age_median'].quantile(0.25))\n",
    "loan_df['living_apartments_avg'] = loan_df['living_apartments_avg'].fillna(loan_df['living_apartments_avg'].quantile(0.25))\n",
    "loan_df['non_living_apartments_avg'] = loan_df['non_living_apartments_avg'].fillna(loan_df['non_living_apartments_avg'].quantile(0.25))\n",
    "loan_df['common_area_median'] = loan_df['common_area_median'].fillna(loan_df['common_area_median'].quantile(0.25))\n",
    "loan_df['elevators_median'] = loan_df['elevators_median'].fillna(loan_df['elevators_median'].quantile(0.25))\n",
    "loan_df['max_floors_median'] = loan_df['max_floors_median'].fillna(loan_df['max_floors_median'].quantile(0.25))\n",
    "loan_df['min_floors_median'] = loan_df['min_floors_median'].fillna(loan_df['min_floors_median'].quantile(0.25))\n",
    "loan_df['land_area_median'] = loan_df['land_area_median'].fillna(loan_df['land_area_median'].quantile(0.25))\n",
    "loan_df['living_apartments_median'] = loan_df['living_apartments_median'].fillna(loan_df['living_apartments_median'].quantile(0.25))\n",
    "loan_df['non_living_apartments_median'] = loan_df['non_living_apartments_median'].fillna(loan_df['non_living_apartments_median'].quantile(0.25))\n",
    "loan_df['non_living_area_median'] = loan_df['non_living_area_median'].fillna(loan_df['non_living_area_median'].quantile(0.25))\n",
    "loan_df['living_area_avg'] = loan_df['living_area_avg'].fillna(loan_df['living_area_avg'].quantile(0.25))\n",
    "loan_df['family_size'] = loan_df['family_size'].fillna(loan_df['family_size'].quantile(0.25))\n",
    "loan_df['non_living_area_avg'] = loan_df['non_living_area_avg'].fillna(loan_df['non_living_area_avg'].quantile(0.25))\n",
    "loan_df['total_area_mode'] = loan_df['total_area_mode'].fillna(loan_df['total_area_mode'].quantile(0.25))\n",
    "loan_df['annuity_amount'] = loan_df['annuity_amount'].fillna(loan_df['annuity_amount'].quantile(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c5869-a830-4e88-87f3-7cb01f4a6263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the 25th percentile\n",
    "loan_df['goods_price'] = loan_df['goods_price'].fillna(loan_df['goods_price'].quantile(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d900c3a-dcfb-4936-b253-25e1bca1cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mode for categorical columns\n",
    "loan_df['max_floors_mode'] = loan_df['max_floors_mode'].fillna(loan_df['max_floors_mode'].mode()[0])\n",
    "loan_df['occupation'] = loan_df['occupation'].fillna(loan_df['occupation'].mode()[0])\n",
    "loan_df['min_floors_mode'] = loan_df['min_floors_mode'].fillna(loan_df['min_floors_mode'].mode()[0])\n",
    "loan_df['elevators_mode'] = loan_df['elevators_mode'].fillna(loan_df['elevators_mode'].mode()[0])\n",
    "loan_df['apartment_average_size'] = loan_df['apartment_average_size'].fillna(loan_df['apartment_average_size'].mode()[0])\n",
    "loan_df['basement_average_area'] = loan_df['basement_average_area'].fillna(loan_df['basement_average_area'].mode()[0])\n",
    "loan_df['years_since_building_use'] = loan_df['years_since_building_use'].fillna(loan_df['years_since_building_use'].mode()[0])\n",
    "loan_df['building_age'] = loan_df['building_age'].fillna(loan_df['building_age'].mode()[0])\n",
    "loan_df['common_area_avg'] = loan_df['common_area_avg'].fillna(loan_df['common_area_avg'].mode()[0])\n",
    "loan_df['elevators_avg'] = loan_df['elevators_avg'].fillna(loan_df['elevators_avg'].mode()[0])\n",
    "loan_df['entrances_avg'] = loan_df['entrances_avg'].fillna(loan_df['entrances_avg'].mode()[0])\n",
    "loan_df['max_floors_avg'] = loan_df['max_floors_avg'].fillna(loan_df['max_floors_avg'].mode()[0])\n",
    "loan_df['min_floors_avg'] = loan_df['min_floors_avg'].fillna(loan_df['min_floors_avg'].mode()[0])\n",
    "loan_df['land_area_avg'] = loan_df['land_area_avg'].fillna(loan_df['land_area_avg'].mode()[0])\n",
    "loan_df['living_apartments_avg'] = loan_df['living_apartments_avg'].fillna(loan_df['living_apartments_avg'].mode()[0])\n",
    "loan_df['non_living_apartments_avg'] = loan_df['non_living_apartments_avg'].fillna(loan_df['non_living_apartments_avg'].mode()[0])\n",
    "loan_df['apartment_mode'] = loan_df['apartment_mode'].fillna(loan_df['apartment_mode'].mode()[0])\n",
    "loan_df['basement_mode'] = loan_df['basement_mode'].fillna(loan_df['basement_mode'].mode()[0])\n",
    "loan_df['years_building_use_mode'] = loan_df['years_building_use_mode'].fillna(loan_df['years_building_use_mode'].mode()[0])\n",
    "loan_df['building_age_mode'] = loan_df['building_age_mode'].fillna(loan_df['building_age_mode'].mode()[0])\n",
    "loan_df['house_fund_mode'] = loan_df['house_fund_mode'].fillna(loan_df['common_area_mode'].mode()[0])\n",
    "loan_df['walls_material_mode'] = loan_df['walls_material_mode'].fillna(loan_df['house_type_mode'].mode()[0])\n",
    "loan_df['emergency_state_mode'] = loan_df['emergency_state_mode'].fillna(loan_df['emergency_state_mode'].mode()[0])\n",
    "loan_df['entrances_mode'] = loan_df['entrances_mode'].fillna(loan_df['entrances_mode'].mode()[0])\n",
    "loan_df['house_type_mode'] = loan_df['house_type_mode'].fillna(loan_df['house_type_mode'].mode()[0])\n",
    "loan_df['occupation'] = loan_df['occupation'].fillna(loan_df['occupation'].mode()[0])\n",
    "loan_df['common_area_mode'] = loan_df['common_area_mode'].fillna(loan_df['common_area_mode'].mode()[0])\n",
    "loan_df['credit_requests_year'] = loan_df['credit_requests_year'].fillna(loan_df['credit_requests_year'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee5430-855c-402c-a1ae-07787d06418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert age from days to years (absolute values to handle negative days)\n",
    "loan_df['employed_years'] = abs(loan_df['days_employed']) / 365.25\n",
    "\n",
    "# Round age_years to the nearest whole number\n",
    "loan_df['employed_years'] = loan_df['employed_years'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba92ff0-3d0f-4b07-9d87-a60e792260ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = loan_df.drop(columns=['client_id', 'loan_status'])\n",
    "y = loan_df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4016fb-af3f-497b-a813-c1ec9ccb59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'total_income',\n",
    "    'credit_amount',\n",
    "    'num_children',\n",
    "    'gender',\n",
    "    'family_status',\n",
    "    'housing_type',\n",
    "    'region_population_relative',\n",
    "    'age_in_days',\n",
    "    'owns_car',\n",
    "    'occupation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625fe49c-0348-4c19-8ed3-c1076f3bad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your feature matrix and target variable\n",
    "X = loan_df[features]\n",
    "y = loan_df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f5402-a77c-4f46-9360-40f96bbb12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "missing_values = loan_df.isnull().sum()\n",
    "# print(missing_values)\n",
    "\n",
    "missing_columns = missing_values[missing_values > 0]\n",
    "print(missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda81649-3c23-4290-9f0b-ebd4e8624381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency encoding for categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    frequency_encoding = X[col].value_counts() / len(X)\n",
    "    X.loc[:, col] = X[col].map(frequency_encoding)\n",
    "\n",
    "# Check lengths again\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a6be1-4584-426a-8021-f8b1727f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_cols = ['gender', 'family_status', 'housing_type', 'owns_car', 'occupation']\n",
    "\n",
    "# Create and save frequency encodings\n",
    "for col in categorical_cols:\n",
    "    # Calculate frequency encoding\n",
    "    frequency_encoding = X[col].value_counts() / len(X)\n",
    "    \n",
    "    # Save frequency encoding\n",
    "    with open(f'{col}_frequency_encoding.pkl', 'wb') as f:\n",
    "        pickle.dump(frequency_encoding, f)\n",
    "    \n",
    "    # Apply frequency encoding to the column\n",
    "    X[col] = X[col].map(frequency_encoding)\n",
    "\n",
    "print(\"Frequency encodings have been created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f30fb-a25e-4398-ae5a-95232fc283e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7e19d-d62c-4ef3-a28b-9f510df65777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[['total_income', 'credit_amount']] = scaler.fit_transform(X_train[['total_income', 'credit_amount']])\n",
    "X_test[['total_income', 'credit_amount']] = scaler.transform(X_test[['total_income', 'credit_amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027541d0-a81a-4e08-a3fa-776f9cf60f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train a Random Forest model with class weights\n",
    "model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Overall Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Approved', 'Approved'], yticklabels=['Not Approved', 'Approved'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# After fitting the model, check the feature names\n",
    "print(\"Features used for training the model:\")\n",
    "print(model.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07280fb1-227d-4d2a-b723-8193401473d9",
   "metadata": {},
   "source": [
    "# Model Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ed206-6343-4674-bcf1-fad049a502ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('machine_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c8df5-b308-46d2-908b-f8ac43b1a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Save the scaler\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "# Save frequency encodings for categorical columns\n",
    "categorical_cols = ['gender', 'family_status', 'housing_type', 'owns_car', 'occupation']\n",
    "for col in categorical_cols:\n",
    "    frequency_encoding = X[col].value_counts() / len(X)\n",
    "    with open(f'{col}_frequency_encoding.pkl', 'wb') as f:\n",
    "        pickle.dump(frequency_encoding, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf71d8-b61c-4adc-ad40-9822baee93c5",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e6dfa-7c33-49c0-bbf3-b6281e9de7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression model\n",
    "log_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "log_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Overall Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Approved', 'Approved'], yticklabels=['Not Approved', 'Approved'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a1dba3-2c24-4184-bd67-55e8ef224df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Handle missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_sm[['total_income', 'credit_amount']] = scaler.fit_transform(X_train_sm[['total_income', 'credit_amount']])\n",
    "X_test[['total_income', 'credit_amount']] = scaler.transform(X_test[['total_income', 'credit_amount']])\n",
    "\n",
    "# Train LinearSVM model\n",
    "svm_model = LinearSVC(random_state=42, class_weight='balanced', max_iter=10000)\n",
    "svm_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Overall Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Approved', 'Approved'], yticklabels=['Not Approved', 'Approved'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efd0fd-986a-454d-9e7f-07a34cb4545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Overall Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Approved', 'Approved'], yticklabels=['Not Approved', 'Approved'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
